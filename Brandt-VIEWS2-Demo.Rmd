---
title: 'VIEWS Data Setup and Modeling Demo '
author: "Patrick T. Brandt\n"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 2
    collapsed: yes
    smooth_scroll: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
description: Data and model specification documentation for ViEWS2 forecasts
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")

# Check file times to see if we need to re-cache
mtime <- function(file, ...) {
  lapply(Sys.glob(c(file, ...)), function(x) file.info(x)$mtime)
}
```

# Introduction

This demo shows how to read and process the initial data from VIEWS / UCDP.  This is based on the data from [VIEWS](https://viewsforecast.org).  Here the files are downloaded from the Dropbox location for the data.  Alternative version would be direct calls to the [API](https://github.com/prio-data/views_api/wiki/Available-datasets).

# Country-Month Data setup

Here begin with setting up the training data as provided by
[ViEWS](https://viewsforecasting.org/prediction-competition-2/). This
takes the data as given from ViEWS and reads it into several data frames
and some subsets.

### Reading in data

Now these are compressed, which means there are only data for all
observations that are observed.

*If you run your own version of this, you will likely need to change the paths to the input files.*  You can get the codebooks and input files [here](https://www.dropbox.com/scl/fo/rurpcmtpcquni5onoyuus/AI6p3CLXEGrRVak2wEsTgAM/codebooks?rlkey=v1o4va647qrwc4la7m8i7cedk&subfolder_nav_tracking=1&st=lnki2qvf&dl=0). 

```{r readdata, echo=TRUE, cache=TRUE, cache.rebuild = !file.exists("cm_features.parquet")}

# CM level data: features and outcomes
dl_link <- "https://www.dropbox.com/scl/fo/rurpcmtpcquni5onoyuus/AM3DF4JXxM3cthQLt-S4pnE/features/cm/cm_features.parquet?rlkey=v1o4va647qrwc4la7m8i7cedk&e=1&st=wtqiw2z5&dl=1"
destfile <- "cm_features.parquet"

# DL with curl
curl::curl_download(url = dl_link, destfile = destfile)

# For the parquet files load the `arrow` package
library(arrow)

# This is the main data file
cm <- read_parquet("cm_features.parquet")

# Get the list of country names as well to add to the data
dl_link2 <- "https://www.dropbox.com/scl/fo/rurpcmtpcquni5onoyuus/AGeR6dD-Ru-Emwn06HnKAE8/matching_tables?preview=countries.csv&rlkey=v1o4va647qrwc4la7m8i7cedk&subfolder_nav_tracking=1&st=goucd0hg&dl=1"

destfile2 <- "country.zip"

# DL with curl
curl::curl_download(url = dl_link2, destfile = destfile2)

# Unzip
zip::unzip(zipfile = "country.zip", exdir="countries")

# Read it
countries <- read.csv("countries/countries.csv", header = TRUE)

# Month to date maps
dl_link3 <- "https://www.dropbox.com/scl/fo/rurpcmtpcquni5onoyuus/AGeR6dD-Ru-Emwn06HnKAE8/matching_tables?preview=month_ids.csv&rlkey=v1o4va647qrwc4la7m8i7cedk&subfolder_nav_tracking=1&st=l8g86mv4&dl=1"

destfile3 <- "month_ids.zip"
curl::curl_download(url = dl_link3, destfile = destfile3)
zip::unzip(zipfile = "month_ids.zip", exdir="month_ids")
month_ids <- read.csv("month_ids/month_ids.csv", header = TRUE)

```

(Note the above will also have downloaded the `pgm` items for the months and the countries, so this is available for later processing.)

## Basic data manipulation for country-months

Here we see how to align the dates and country codes so that the identifiers can always be put back into the data for case identifications.  This is a set of `merge` commands using base R.

```{r mergething, echo=TRUE}

# Subset out the main (conflict) variables we want
df1 <- subset(cm, select = c(month_id, country_id,
                             gleditsch_ward,
                             ged_sb, ged_ns, ged_os, 
                             acled_sb, acled_sb_count, acled_os))

# Merge on the country label data
dfs <- merge(df1, countries, 
             by.x = "country_id", by.y="id")

# Merge on the time periods info
dfs <- merge(dfs, month_ids[,2:4],
             by.x = "month_id", by.y="month_id")

# Clean up
rm(df1,cm)

```


# Basic Time Series Plots of all the SB killings data

This summarizes and plots the GED state-based (SB) deaths series.

```{r demoplots, echo=TRUE, cache=TRUE, fig.keep='all'}
#### Simple plots as checks ####

# Simple summary plot to see that we have things correct...
ms <- sort(unique(dfs$month_id))

roll.ged.sb <- matrix(NA, nrow=length(ms), ncol=3)
sbdata <- vector(mode="list", length=length(ms))

for(i in 1: length(ms))
{
  sb <- dfs[dfs$month_id==ms[i],]$ged_sb 
  sbdata[[i]] <- as.vector(unlist(sb))
  roll.ged.sb[i,] <- c(ms[i], mean(sbdata[[i]]), sd(sbdata[[i]]))
}

rm(sb)

roll.ged.sb <- ts(roll.ged.sb[,2:3], start=c(1990,1), freq=12)

colnames(roll.ged.sb) <- c("Mean SB", "Std.Dev. SB")

plot(roll.ged.sb, lwd=2, col=1:2, main="", 
     cex.lab=0.9, cex.axis=0.7)
```



# Distributional summaries

Here we look at the main variable from GED, the state-based deaths in the `ged_sb` variable.  (This can be repeated later for the other target measures in the `dfs` object.)

One can generate the `Unknown Pleasures` plot using the demo from [here](https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html). 

```{r distrosums, echo=TRUE}
library(dplyr)
library(ggplot2)
library(ggridges)

# Plot the distributions by year
ggplot(dfs, aes(x = ged_sb, y = Year, group = Year)) +
  geom_density_ridges(panel_scaling = TRUE)



```

(This last plot needs some work on its aesthetics.  The idea is to show that the modes are the same, but the tails vary widely.)

## Fit Tweedie models

**Describe Tweedie and EDM models here**. 

This is a stability check on the data: can we even really generalize an ED like target density?  Do the parameters of the Tweedie fitted model to the data change or stay the same over time (months)?

```{r rolltw, include=TRUE}
library(tweedie)
library(statmod)

oneperiod.fit <- function(y, xi.vec=seq(1.45, 1.775, by=0.005))
{
  out <- tweedie.profile(y~1, xi.vec=xi.vec, 
                         do.plot=FALSE, do.smooth=FALSE,
                         glm.control(maxit=100),
                         method="series")
  return(list(phi = out$phi.max, xi = out$xi.max))
}


# Do explicit parallelization here over nodes.  
# Note this can be made more elegant with the `parallel` package.

library(snow)

nodes <- 8 # Number of cores to use in parallel
cl <- makeCluster(spec=nodes, type="SOCK")
clusterEvalQ(cl, library(tweedie))
clusterSetupRNGstream(cl)
#clusterExport(cl, "xi.vec")
clusterExport(cl, "oneperiod.fit")

# Now fit them all at once!
system.time(all.tw <- clusterApplyLB(cl, sbdata, oneperiod.fit))

stopCluster(cl)
                    
```

## Time series parameter summaries

Plot summaries of the key parameters of the Tweedie models for each time period (month).

```{r summs, include=TRUE, fig.height=6, fig.keep='last'}
# Now summarize the results
all.tw.sum <- matrix(unlist(all.tw), ncol=2, byrow = TRUE)

# Now make some plots to see what changes over time

twp <- cbind(roll.ged.sb, all.tw.sum)
colnames(twp) <- c("Mean", "Std Dev.", "phi", "p")

# Make a plot to see what changes over time
plot(twp, main="")

```


Now plot the probability of a zero count from the Tweedie, Poisson, and data for comparison.


```{r zeropred, echo=TRUE, fig.width=6, fig.keep='last'}

# Convert using Dunn and Smyth formula
twp.convert <- sapply(1:nrow(twp), 
                      function(i) tweedie.convert(xi = twp[i,"p"], 
                                                  mu=twp[i,"Mean"], 
                                                  phi=twp[i,"phi"]),
                     USE.NAMES = FALSE)

twp.convert <- as.data.frame(matrix(unlist(twp.convert), 
                                    ncol=6, byrow=TRUE))
colnames(twp.convert) <- c("poisson.lambda", 
                           "gamma.scale", "gamma.shape",
                           "p0", "gamma.mean", "gamma.phi")

# Compute the observed zeros proportion by month and plot against the predictions:
freq.zeros <- aggregate(dfs$ged_sb==0,
                        by=list(dfs$month_id), mean)

# Poisson predictions make no sense
# range(dpois(0, lambda=roll.ged.sb[,1]))

plot(ts(cbind(twp.convert$p0, freq.zeros[,2]), 
        start=c(1990,1), freq=12),
     plot.type="single", lwd=2, lty=2:3, col=2:1, 
     ylab = "Pr(ged_sb=0)")

legend(2013, 0.925, 
       c("Observed Frequency", "Tweedie Prediction"), col=2:1,
       lty=2:3, lwd=2, cex=0.75)

```

# Simple prediction models

This section shows how to set up some simple baseline prediction models for each country-month in the data.

### Basic count regressions

This section sets up a series of count regression models.  It assumes you split the data into training-test splits and fit the following models:

- P = Poisson 
- NB = Negbin
- ZIP = ZI Poisson
- ZINB = ZI Negbin
- TW = Tweedie 

This is all done via the `count.cf` function defined below.  The result is a set of `N` simulated draws from the forecast density for each model and outcome to be predicted in the test data.

```{r basiccounts, echo=TRUE, message=FALSE}
# Load needed libraries
library(statmod)
library(tweedie)
library(MASS)
library(pscl)
library(zoo)

set.seed(145)


# count.cf -- fits a single count model to a series and validates it
# against a training / test setup with forecast metrics
#
# Fits each count regression model on train-test data for
# P = Poisson 
# NB = Negbin
# ZIP = ZI Poisson
# ZINB = ZI Negbin
# TW = Tweedie 
#
# After MLE fits, generates and returns N draws from the prediction
# density for each of these models
#

count.cf <- function(train, test, xi.vec = seq(1.1, 1.75, by=0.025), 
                     N = 1000)
{
  # Fit models
  p <- glm(y ~ geo, family = poisson, data=train)
  nb <- glm.nb(y ~ geo, data=train)
  zip <- zeroinfl(y ~ geo, data=train, dist="poisson", model=FALSE, y = FALSE)
  zinb <- zeroinfl(y ~ geo, data=train, dist="negbin", model=FALSE, y = FALSE)
  #  zgeom <- zeroinfl(y ~ 1, data=train, dist="geometric", model=FALSE, y = FALSE)
  
  cat("Fitting Tweedie model grid for xi:\n")  
  param.tw <- tweedie.profile(y ~ geo, xi.vec=xi.vec, 
                              data = train,
                              do.plot=FALSE,
                              control=list(maxit=50),
                              method="series", verbose=FALSE)
  tw <- glm(y ~ geo, data = train,
            family=tweedie(var.power=param.tw$xi.max, link.power=0),
            control=list(maxit=50))
  
  # Predict forecasts for test periods
  n <- nrow(test)
  p.p <- predict(p, newdata=test, type="response")
  p.nb <- predict(nb, newdata=test, type="response")  
  p.zip <- predict(zip, newdata=test, type="response")
  p.zinb <- predict(zinb, newdata=test, type="response")
  #  p.zgeom <- predict(zgeom, newdata=test, type="response")
  p.tw <- predict(tw, newdata=test, type = "response")
  
  # Now simulate the forecasts for each test period
  cat("Sampling forecast densities")
  p.sample <- t(sapply(1:n, function(i) {rpois(N, lambda=p.p[i])}))  
  cat(" .")
  nb.sample <- t(sapply(1:n, function(i) {rnbinom(N, size=nb$theta, mu=p.nb[i])}))
  cat(" .")
  zip.sample <- t(sapply(1:n, function(i) {rpois(N, lambda=p.zip[i])}))
  cat(" .")
  zinb.sample <- t(sapply(1:n, function(i) {rnbinom(N, size=zinb$theta, mu=p.zinb[i])}))  
  cat(" .\n")
  tw.sample <- t(sapply(1:n, function(i) {rtweedie(N, xi=param.tw$xi.max,
                                                   mu=p.tw[i], phi=1) }))
  
  # Some cleanups
  rm(p,nb,zip,zinb,tw,
     p.p,p.nb,p.zip,p.zinb,p.tw)
  
  return(list(P = p.sample,
              NB = nb.sample,
              ZIP = zip.sample,
              ZINB = zinb.sample,
              TW = tw.sample))
}

```

## Simple demo of the count model comparisons

```{r countdemo1, echo=TRUE, warning=FALSE}

# Define a DV as a simple variable and a factor for the countries
dfs$y <- dfs$ged_sb
dfs$geo <- as.factor(dfs$country_id)

# Splits and subsets
train <- dfs[dfs$Year>2020 & dfs$Year < 2024,]
test <- dfs[dfs$Year>2023,]

# Now fit models over the subsets
system.time(count.out <- count.cf(train, test, N=1000))

```


### Count regressions with GAM / splines / GLMMs

This section demonstrates the approach taken in Brandt (2024).   Here an illusration of a basic model with GAM / GLMM components are illustrated and then compared to the earlier section's analyses.

# Scoring forecasts

Here's how one can compute scoring rules to rank the forecasts from each of the models.  This is akin to Brandt (n.d.).

### Scoring with simple metrics

- RMSE
- Divergence
- Brier Scores
- AUROC
- CRPS

### CRPS

```{r scoringdemo, echo=TRUE, message=FALSE, warning=FALSE}
library(scoringutils)

# Get the mean CRPS values across the country-year-draws
check.crps <- lapply(lapply(count.out, 
                                  crps_sample, 
                                  observed = test$y), mean)

# Show the CRPS for the test data
print(unlist(check.crps), digits = 3)

```

## Metrics over time horizons

## Benchmarks comparisons

## Skill scores

# `cm` models with covariates

## Climate

## Demography

## Civil-Military Expenditures




# PRIO-Grid Month (`pgm`) Data setup

## Analyses like above for some `pgm`
